{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montana banks PDF parser\n",
    "\n",
    "A basic example of using [`pdfplumber`](https://github.com/jsvine/pdfplumber) to extract data from a PDF. We'll parse [a short PDF of state-chartered banks in Montana](http://banking.mt.gov/Portals/58/Bank_List.pdf) and flatten the data so that one record = one branch, then write out to JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the PDF lives online\n",
    "URL = 'http://banking.mt.gov/Portals/58/Bank_List.pdf'\n",
    "\n",
    "# path to the file we'll download the PDF as\n",
    "PDF = 'mtbanks.pdf'\n",
    "\n",
    "# path to the JSON file we'll write out to\n",
    "JSON = 'mtbanks.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL)\n",
    "r.raise_for_status()\n",
    "\n",
    "with open(PDF, 'wb') as o:\n",
    "    for block in r.iter_content(1024):\n",
    "        o.write(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to extract table data from one page\n",
    "\n",
    "Each branch record will have the name of the bank, the city, the state and a boolean showing whether it's the main branch. The \"other branch\" cell gets split by state, then by city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_data(page):\n",
    "    '''Given a page of the bank list PDF, extract the data and return a list of dictionaries'''\n",
    "\n",
    "    keys = ['bank_name', 'city', 'state', 'main_branch']\n",
    "    data = []\n",
    "    \n",
    "    table = page.extract_table()\n",
    "    \n",
    "    for row in table[1:]:\n",
    "        bankname, main_branch, other_branches = row\n",
    "        bankname_clean = bankname.replace(' (continued)', '')\n",
    "\n",
    "        if main_branch:\n",
    "            data.append(dict(zip(keys, [bankname_clean, main_branch, 'Montana', True])))\n",
    "\n",
    "        if other_branches:\n",
    "            split_by_state = other_branches.split('\\n \\n')\n",
    "            for s in split_by_state:\n",
    "                citysplit = s.split(':')\n",
    "                if len(citysplit) == 2:\n",
    "                    state, cities = citysplit\n",
    "                else:\n",
    "                    state = 'Montana'\n",
    "                    cities = citysplit[0]\n",
    "                city_list = cities.split(',')\n",
    "                clean_list = [x.strip().replace('\\n', '') for x in city_list if x.strip()]\n",
    "                \n",
    "                for city in clean_list:\n",
    "                    data.append(dict(zip(keys, [bankname_clean, city, state.title(), False])))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roll through the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the PDF and the JSON file we're writing out to\n",
    "with pdfplumber.open(PDF) as p, open(JSON, 'w') as js:\n",
    "    \n",
    "    # get the updated date from the top matter\n",
    "    firstpage = p.pages[0]\n",
    "    top_info = (0, 0, firstpage.width, 100)\n",
    "    chars = p.pages[0].crop(top_info).objects['char']\n",
    "    updated = ''.join([x['text'] for x in chars]).split('As of ')[-1].strip()\n",
    "    u_date = datetime.strptime(updated, '%B %d, %Y').date()\n",
    "    \n",
    "    # the dict we're gonna write out to\n",
    "    banks = {\n",
    "        'updated': str(u_date),\n",
    "        'data': []\n",
    "    }\n",
    "    \n",
    "    # loop over the pages\n",
    "    for page in p.pages:\n",
    "        # call the extract function\n",
    "        data = extract_table_data(page)\n",
    "        \n",
    "        # add to the `data` list inside the `banks` dict\n",
    "        banks['data'].extend(data)\n",
    "        \n",
    "    # write to file\n",
    "    js.write(json.dumps(banks))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
